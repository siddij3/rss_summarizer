https://garymarcus.substack.com/p/elegant-and-powerful-new-result-that: A study led by Owain Evans indicates that large language models (LLMs) struggle to infer symmetrical relationships, a situation that reflects flaws in these systems and questions progress towards Artificial General Intelligence. This issue, rooted in the history of neural networks, reveals that they can't extrapolate beyond their training examples. Despite specific prompts aiding correct responses, LLMs fail to generalize facts from one context to another, suggesting the need for new approaches such as neurosymbolic mechanisms or knowledge graphs.
,
https://forum.effectivealtruism.org/posts/xJYRiy8Jjy2Tk2qHr/intro-to-ai-risk-for-ai-grad-students: The article is a statement from a lecturer who will be delivering a presentation on AI safety for over 50 incoming AI graduate students at a university. The lecture aims to familiarize students with AI safety basics to spur knowledgeable discussions and influence their research topic choices. Students are encouraged to do some reading post-lecture for better comprehension. The lecturer acknowledges the resources provided by the AI Safety Fundamentals team and invites further help from the community. The broader goal is promoting safe AI practices for humanity's greater good.,
https://forum.effectivealtruism.org/posts/QDMGLxR6Wsjoqpi25/report-proposals-for-the-prevention-and-detection-of: Emerging infectious diseases (EIDs) are on the rise due to factors like globalization, population growth, and environmental damage. Most of these diseases are zoonotic and pose a major public health risk. Guatemala is a hotspot for EIDs due to its climate, biodiversity, urbanization, and dense population. Diseases like dengue fever and avian influenza are common and exacerbated by local farming practices. Poor sanitation and inadequate health infrastructure further spread these diseases. To combat EIDs, strategies include improved sanitation, surveillance, testing, curbing wildlife trade, halting deforestation, and responsible antibiotic use. Though costs are a concern, incorporating scientific approaches can create feasible solutions.
,
https://blog.ml.cmu.edu/2023/09/22/supporting-human-ai-collaboration-in-auditing-llms-with-llms/: The article discusses the importance of auditing large language models (LLMs) like ChatGPT, given their increasing usage. Existing auditing tools fail to effectively include the human element. The AdaTest++ tool was designed to leverage human effort and AI in the auditing process more efficiently. Recent studies with AdaTest++ showed people discovering a variety of model failures regularly and efficiently. It highlights that as LLMs become more prevalent, understanding their failure modes will be critical to establishing safe usage boundaries. The tool was developed in collaboration with researchers from Google DeepMind, and Microsoft Research.
,
